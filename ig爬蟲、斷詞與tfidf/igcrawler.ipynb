{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ac099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver import DesiredCapabilities\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "#設置option\n",
    "option = webdriver.ChromeOptions()\n",
    "#不加載圖片\n",
    "option.add_argument('blink-settings=imagesEnabled=false')\n",
    "\n",
    "driver = webdriver.Chrome(options=option)\n",
    "\n",
    "driver.get(\"https://www.instagram.com/\")# 定位搜尋框，前往該頁面\n",
    "username = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.NAME, \"username\"))\n",
    "    )\n",
    "password = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.NAME, \"password\"))\n",
    "    )\n",
    "\n",
    "#等到username和password標籤出來後再繼續執行下個動作\n",
    "login = driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[3]') #定義登入按鈕的標籤\n",
    "username.clear()\n",
    "password.clear()\n",
    "#清除在該標籤的預設文字\n",
    "username.send_keys('請出入你的ig帳號')\n",
    "password.send_keys('請輸入你的ig密碼')\n",
    "#send_keys為輸入()內的文字進入該標籤\n",
    "login.click() #點擊登入\n",
    "time.sleep(4)\n",
    "#輸入網址導到你要的頁面\n",
    "driver.get(\"https://www.instagram.com/explore/tags/%E5%8F%B0%E6%9D%B1%E5%A4%A7%E5%AD%B8/\")\n",
    "\n",
    "\n",
    "#=========================================================================================================\n",
    "\n",
    "#創建array\n",
    "first_content = np.array([], dtype=str)\n",
    "first_date = np.array([], dtype=str)\n",
    "\n",
    "#點選第一個貼文\n",
    "click_post = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"_9AhH0\"))\n",
    "    )\n",
    "click_post.click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "#抓貼文內容\n",
    "first_content_element = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"C4VMK\"))\n",
    "    )\n",
    "#抓貼文時間\n",
    "post_time = driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div/div[2]/div[2]/a/time').get_attribute('title')\n",
    "#存入array\n",
    "first_content = np.append(first_content, first_content_element.text)\n",
    "first_date = np.append(first_date, post_time)\n",
    "                          \n",
    "#===========================================================================================================\n",
    "#點選右箭頭到下一篇貼文\n",
    "time.sleep(4)\n",
    "click_arrow1 = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH,\"/html/body/div[6]/div[1]/div/div/div/button/div\")))\n",
    "click_arrow1.click()\n",
    "time.sleep(3)\n",
    "#將貼文內容與日期儲存\n",
    "first_content_element = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"C4VMK\"))\n",
    "    )\n",
    "post_time = driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div/div[2]/div[2]/a/time').get_attribute('title')\n",
    "\n",
    "#將上面兩篇的貼文內容與日期合併\n",
    "first_content = np.append(first_content, first_content_element.text)\n",
    "first_date = np.append(first_date, post_time)\n",
    "#先將first_date儲存\n",
    "out = pd.DataFrame({'date': first_date, 'contents': first_content})\n",
    "out.to_excel('專屬黃昇宏的台東大學ig貼文內容first.xlsx', encoding=\"utf_8_sig\")\n",
    "time.sleep(4)\n",
    "delay_choices = [15, 13, 17, 20, 10]\n",
    "#===============================================================================================================\n",
    "def crawler(x):\n",
    "    for d in range(1):\n",
    "        #設定存放內容與日期的變數\n",
    "        contents = np.array([], dtype=str)\n",
    "        dates = np.array([], dtype=str)\n",
    "        for i in tqdm(range(200)):\n",
    "            \n",
    "                #try and except\n",
    "                try:\n",
    "                    #設定隨機延遲\n",
    "                    \n",
    "                    delay = random.choice(delay_choices)\n",
    "                    #點選右箭頭到下一篇貼文(這裡的右箭頭xpath不一樣所以要重新定義)\n",
    "                    click_arrow2 = WebDriverWait(driver, 120).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, \"/html/body/div[6]/div[1]/div/div/div[2]/button/div/span\"))\n",
    "                    )\n",
    "                    click_arrow2.click()\n",
    "                    # 抓取貼文的content class\n",
    "                    post_content_element = WebDriverWait(driver, 120).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"C4VMK\"))\n",
    "                    )\n",
    "                    #抓取日期\n",
    "                    post_time2 = driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div/div[2]/div[2]/a/time').get_attribute('title')\n",
    "\n",
    "                    #將資料與日期加入變數\n",
    "                    contents = np.append(contents, post_content_element.text)\n",
    "                    dates = np.append(dates, post_time2)\n",
    "                    time.sleep(delay)\n",
    "                    \n",
    "                except:\n",
    "                    print('第' + str(i) + '個網址錯誤')\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "        #將資料存在csv\n",
    "        output = pd.DataFrame({'date': dates, 'contents': contents})\n",
    "        output.to_excel('專屬黃昇宏的台東大學ig貼文內容' + str(x) + '.xlsx', encoding=\"utf_8_sig\")\n",
    "        #跳出迴圈\n",
    "        print('download complete')\n",
    "        \n",
    "for i in range(10):\n",
    "    crawler(i)\n",
    "    time.sleep(300)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b5c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2,df3],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748c225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251fabc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow(python3.8)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
